{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO8Aq0pbBLvNC6bW9+0tin7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"717fc7e80cba4753b350a5774fe4ed4b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_632f16073af7425282c952af659bb43e","IPY_MODEL_787141c42b0b4fcdab913f3d59c773a5","IPY_MODEL_63721dc713ec4d5782bac7987340a935"],"layout":"IPY_MODEL_72b6a89442044de2ae5631aaa9967820"}},"632f16073af7425282c952af659bb43e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fae96859a0204fb1a64c17a8d8d68bdb","placeholder":"​","style":"IPY_MODEL_40c9998813274bd995a089cd34d587d6","value":"Map: 100%"}},"787141c42b0b4fcdab913f3d59c773a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dd2cefb1e714030b98ce7e668173a38","max":25000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04ee4c793e0b45d0a6f97eac8c44313b","value":25000}},"63721dc713ec4d5782bac7987340a935":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ddc18ff2d5244c393cac7fcb2c01547","placeholder":"​","style":"IPY_MODEL_801aa4ce3fc74245aece0fc9492f6ee6","value":" 25000/25000 [00:37&lt;00:00, 641.92 examples/s]"}},"72b6a89442044de2ae5631aaa9967820":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fae96859a0204fb1a64c17a8d8d68bdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40c9998813274bd995a089cd34d587d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6dd2cefb1e714030b98ce7e668173a38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04ee4c793e0b45d0a6f97eac8c44313b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ddc18ff2d5244c393cac7fcb2c01547":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"801aa4ce3fc74245aece0fc9492f6ee6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b45d837e12c24d128ce982477f956368":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6dfcb90ebcfd4c498058d2ac0ba7308e","IPY_MODEL_103c0ba0e51345d8b8f9ad9cea053c4e","IPY_MODEL_4313cb6cc22d4e159d7e5440a7b3ef99"],"layout":"IPY_MODEL_81025478dd4149c78dbb2afcb3fb4e31"}},"6dfcb90ebcfd4c498058d2ac0ba7308e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e86002fafb6344aa94601aefce05298a","placeholder":"​","style":"IPY_MODEL_d132fd2ff9b548f8b69da5e77a3305ef","value":"Map: 100%"}},"103c0ba0e51345d8b8f9ad9cea053c4e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8617d93d29f74254a71a739dd47b823b","max":25000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1915979bc24b4938a5595db4e1d36517","value":25000}},"4313cb6cc22d4e159d7e5440a7b3ef99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9907fe7e909e4094aa3e6c79dee28953","placeholder":"​","style":"IPY_MODEL_86893147d9d347eca4bea7d45f2a9fcc","value":" 25000/25000 [00:36&lt;00:00, 668.97 examples/s]"}},"81025478dd4149c78dbb2afcb3fb4e31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e86002fafb6344aa94601aefce05298a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d132fd2ff9b548f8b69da5e77a3305ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8617d93d29f74254a71a739dd47b823b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1915979bc24b4938a5595db4e1d36517":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9907fe7e909e4094aa3e6c79dee28953":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86893147d9d347eca4bea7d45f2a9fcc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb1534e4c07447f5b0590395908685bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dcd03856d3454fa99a0077e6343cc49a","IPY_MODEL_b65782cba9f04ecbb06cabb47dd0ec1c","IPY_MODEL_e131c58cdb054e98bb17533207014f1c"],"layout":"IPY_MODEL_2a50533d374249c7ba184fdb6cd56806"}},"dcd03856d3454fa99a0077e6343cc49a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_189b7b61700147d69e4ab3bf6b7d9d43","placeholder":"​","style":"IPY_MODEL_3c13d30b6b544b95b54a91f8272e0a6b","value":"Map: 100%"}},"b65782cba9f04ecbb06cabb47dd0ec1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f88eef818c1461dbf5ca64947d920f3","max":50000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e7e76f474c224eb2ad7840cda798f340","value":50000}},"e131c58cdb054e98bb17533207014f1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95d8e6a3c7e047d8a666e1226b062421","placeholder":"​","style":"IPY_MODEL_27bba64a6cbd493d964bbe56e4b18b5d","value":" 50000/50000 [00:56&lt;00:00, 1052.52 examples/s]"}},"2a50533d374249c7ba184fdb6cd56806":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"189b7b61700147d69e4ab3bf6b7d9d43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c13d30b6b544b95b54a91f8272e0a6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f88eef818c1461dbf5ca64947d920f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7e76f474c224eb2ad7840cda798f340":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"95d8e6a3c7e047d8a666e1226b062421":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27bba64a6cbd493d964bbe56e4b18b5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":809},"id":"pyboc0gYUxg9","executionInfo":{"status":"ok","timestamp":1728243287548,"user_tz":240,"elapsed":25840,"user":{"displayName":"Ken Clements","userId":"01172872815397642559"}},"outputId":"bd38603f-505a-425a-8470-212717e06877"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional_8\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │      \u001b[38;5;34m5,120,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ positional_encoding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","│ (\u001b[38;5;33mPositionalEncoding\u001b[0m)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder_layer │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │      \u001b[38;5;34m9,453,568\u001b[0m │ positional_encoding[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mTransformerEncoderLayer\u001b[0m) │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │      \u001b[38;5;34m9,453,568\u001b[0m │ transformer_encoder_l… │\n","│ (\u001b[38;5;33mTransformerEncoderLayer\u001b[0m) │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │      \u001b[38;5;34m5,120,000\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │      \u001b[38;5;34m9,453,568\u001b[0m │ transformer_encoder_l… │\n","│ (\u001b[38;5;33mTransformerEncoderLayer\u001b[0m) │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ positional_encoding_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","│ (\u001b[38;5;33mPositionalEncoding\u001b[0m)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │      \u001b[38;5;34m9,453,568\u001b[0m │ transformer_encoder_l… │\n","│ (\u001b[38;5;33mTransformerEncoderLayer\u001b[0m) │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_decoder_layer │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m17,856,000\u001b[0m │ positional_encoding_1… │\n","│ (\u001b[38;5;33mTransformerDecoderLayer\u001b[0m) │                        │                │ transformer_encoder_l… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_decoder_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m17,856,000\u001b[0m │ transformer_decoder_l… │\n","│ (\u001b[38;5;33mTransformerDecoderLayer\u001b[0m) │                        │                │ transformer_encoder_l… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_decoder_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m17,856,000\u001b[0m │ transformer_decoder_l… │\n","│ (\u001b[38;5;33mTransformerDecoderLayer\u001b[0m) │                        │                │ transformer_encoder_l… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_decoder_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m17,856,000\u001b[0m │ transformer_decoder_l… │\n","│ (\u001b[38;5;33mTransformerDecoderLayer\u001b[0m) │                        │                │ transformer_encoder_l… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_16 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m10000\u001b[0m)      │      \u001b[38;5;34m5,130,000\u001b[0m │ transformer_decoder_l… │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ positional_encoding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncoding</span>)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder_layer │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,453,568</span> │ positional_encoding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderLayer</span>) │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,453,568</span> │ transformer_encoder_l… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderLayer</span>) │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,000</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,453,568</span> │ transformer_encoder_l… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderLayer</span>) │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ positional_encoding_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncoding</span>)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,453,568</span> │ transformer_encoder_l… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderLayer</span>) │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_decoder_layer │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,856,000</span> │ positional_encoding_1… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderLayer</span>) │                        │                │ transformer_encoder_l… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_decoder_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,856,000</span> │ transformer_decoder_l… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderLayer</span>) │                        │                │ transformer_encoder_l… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_decoder_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,856,000</span> │ transformer_decoder_l… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderLayer</span>) │                        │                │ transformer_encoder_l… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_decoder_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,856,000</span> │ transformer_decoder_l… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderLayer</span>) │                        │                │ transformer_encoder_l… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130,000</span> │ transformer_decoder_l… │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m124,608,272\u001b[0m (475.34 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,608,272</span> (475.34 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m124,608,272\u001b[0m (475.34 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,608,272</span> (475.34 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Embedding, MultiHeadAttention, LayerNormalization, Dense, Dropout\n","import numpy as np\n","\n","# Positional Encoding\n","class PositionalEncoding(tf.keras.layers.Layer):\n","    def __init__(self, sequence_length, embedding_dim):\n","        super(PositionalEncoding, self).__init__()\n","        self.sequence_length = sequence_length\n","        self.embedding_dim = embedding_dim\n","        self.positional_encoding = self.compute_positional_encoding()\n","\n","    def compute_positional_encoding(self):\n","        pos = np.arange(self.sequence_length)[:, np.newaxis]\n","        i = np.arange(self.embedding_dim)[np.newaxis, :]\n","        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(self.embedding_dim))\n","        angle_rads = pos * angle_rates\n","\n","        # Apply sin to even indices and cos to odd indices\n","        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","        positional_encoding = angle_rads[np.newaxis, ...]\n","        return tf.cast(positional_encoding, dtype=tf.float32)\n","\n","    def call(self, inputs):\n","        return inputs + self.positional_encoding[:, :tf.shape(inputs)[1], :]\n","\n","# Transformer Encoder Layer\n","class TransformerEncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, embedding_dim, num_heads, ff_dim, rate=0.1):\n","        super(TransformerEncoderLayer, self).__init__()\n","        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)\n","        self.ffn = tf.keras.Sequential([\n","            Dense(ff_dim, activation='relu'),\n","            Dense(embedding_dim)\n","        ])\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","\n","    def call(self, inputs, training, mask):\n","        # Multi-head self-attention\n","        attn_output = self.mha(inputs, inputs, inputs, attention_mask=mask)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","\n","        # Feed-forward network\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","# Transformer Decoder Layer\n","class TransformerDecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, embedding_dim, num_heads, ff_dim, rate=0.1):\n","        super(TransformerDecoderLayer, self).__init__()\n","        self.mha1 = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)\n","        self.mha2 = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)\n","        self.ffn = tf.keras.Sequential([\n","            Dense(ff_dim, activation='relu'),\n","            Dense(embedding_dim)\n","        ])\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","        self.dropout3 = Dropout(rate)\n","\n","    def call(self, inputs, enc_output, training, look_ahead_mask, padding_mask):\n","        # Multi-head self-attention (for the target sequence)\n","        attn1 = self.mha1(inputs, inputs, inputs, attention_mask=look_ahead_mask)\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(inputs + attn1)\n","\n","        # Multi-head cross-attention (attends to the encoder output)\n","        attn2 = self.mha2(out1, enc_output, enc_output, attention_mask=padding_mask)\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(out1 + attn2)\n","\n","        # Feed-forward network\n","        ffn_output = self.ffn(out2)\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        return self.layernorm3(out2 + ffn_output)\n","\n","# Transformer Model\n","def build_transformer(vocab_size, sequence_length, embedding_dim, num_heads, ff_dim, num_layers, rate=0.1):\n","    inputs = tf.keras.Input(shape=(sequence_length,))\n","    targets = tf.keras.Input(shape=(sequence_length,))\n","\n","    # Embedding + Positional Encoding for input and target sequences\n","    enc_embedding = Embedding(vocab_size, embedding_dim)(inputs)\n","    dec_embedding = Embedding(vocab_size, embedding_dim)(targets)\n","\n","    enc_positional = PositionalEncoding(sequence_length, embedding_dim)(enc_embedding)\n","    dec_positional = PositionalEncoding(sequence_length, embedding_dim)(dec_embedding)\n","\n","    enc_output = enc_positional\n","    for _ in range(num_layers):\n","        enc_output = TransformerEncoderLayer(embedding_dim, num_heads, ff_dim, rate)(enc_output, training=True, mask=None)\n","\n","    dec_output = dec_positional\n","    for _ in range(num_layers):\n","        dec_output = TransformerDecoderLayer(embedding_dim, num_heads, ff_dim, rate)(dec_output, enc_output, training=True, look_ahead_mask=None, padding_mask=None)\n","\n","    outputs = Dense(vocab_size)(dec_output)\n","\n","    model = tf.keras.Model(inputs=[inputs, targets], outputs=outputs)\n","    return model\n","\n","# Example hyperparameters\n","vocab_size = 10000\n","sequence_length = 20\n","embedding_dim = 512\n","num_heads = 8\n","ff_dim = 1024\n","num_layers = 4\n","\n","# Build the model\n","transformer = build_transformer(vocab_size, sequence_length, embedding_dim, num_heads, ff_dim, num_layers)\n","\n","# Compile the model\n","transformer.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Print model summary\n","transformer.summary()\n"]},{"cell_type":"code","source":["# prompt: see gpu type\n","\n","!nvidia-smi\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1zYZftSbVpaK","executionInfo":{"status":"ok","timestamp":1728245076673,"user_tz":240,"elapsed":349,"user":{"displayName":"Ken Clements","userId":"01172872815397642559"}},"outputId":"a2618c71-0702-4ee6-913b-d256a489b1f9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Oct  6 20:04:36 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# Install the necessary libraries first if you haven't already\n","# !pip install transformers datasets torch scikit-learn\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import accuracy_score\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n","from datasets import load_dataset\n","\n","# Load the IMDB dataset\n","dataset = load_dataset(\"imdb\")\n","\n","# Initialize TinyBERT tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\", num_labels=2)\n","\n","# Tokenization function\n","def tokenize_function(examples):\n","    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n","\n","# Tokenizing the dataset\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)\n","tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n","\n","# Creating DataLoaders\n","train_loader = DataLoader(tokenized_datasets[\"train\"], batch_size=16, shuffle=True)\n","test_loader = DataLoader(tokenized_datasets[\"test\"], batch_size=16)\n","\n","# Moving model to GPU if available\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)\n","\n","# Defining the optimizer\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","\n","# Training loop\n","model.train()\n","for epoch in range(3):  # Number of epochs\n","    for batch in train_loader:\n","        optimizer.zero_grad()  # Clear gradients\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['label'].to(device)\n","\n","        # Forward pass\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()  # Backpropagation\n","        optimizer.step()  # Update weights\n","\n","    print(f\"Epoch {epoch + 1}: Loss = {loss.item()}\")\n","\n","# Evaluation\n","model.eval()\n","predictions = []\n","true_labels = []\n","\n","with torch.no_grad():\n","    for batch in test_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","\n","        # Forward pass\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predicted_labels = torch.argmax(logits, dim=1).cpu().numpy()\n","\n","        predictions.extend(predicted_labels)\n","        true_labels.extend(batch['label'].numpy())\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(true_labels, predictions)\n","print(f\"Test Accuracy: {accuracy:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312,"referenced_widgets":["717fc7e80cba4753b350a5774fe4ed4b","632f16073af7425282c952af659bb43e","787141c42b0b4fcdab913f3d59c773a5","63721dc713ec4d5782bac7987340a935","72b6a89442044de2ae5631aaa9967820","fae96859a0204fb1a64c17a8d8d68bdb","40c9998813274bd995a089cd34d587d6","6dd2cefb1e714030b98ce7e668173a38","04ee4c793e0b45d0a6f97eac8c44313b","3ddc18ff2d5244c393cac7fcb2c01547","801aa4ce3fc74245aece0fc9492f6ee6","b45d837e12c24d128ce982477f956368","6dfcb90ebcfd4c498058d2ac0ba7308e","103c0ba0e51345d8b8f9ad9cea053c4e","4313cb6cc22d4e159d7e5440a7b3ef99","81025478dd4149c78dbb2afcb3fb4e31","e86002fafb6344aa94601aefce05298a","d132fd2ff9b548f8b69da5e77a3305ef","8617d93d29f74254a71a739dd47b823b","1915979bc24b4938a5595db4e1d36517","9907fe7e909e4094aa3e6c79dee28953","86893147d9d347eca4bea7d45f2a9fcc","eb1534e4c07447f5b0590395908685bb","dcd03856d3454fa99a0077e6343cc49a","b65782cba9f04ecbb06cabb47dd0ec1c","e131c58cdb054e98bb17533207014f1c","2a50533d374249c7ba184fdb6cd56806","189b7b61700147d69e4ab3bf6b7d9d43","3c13d30b6b544b95b54a91f8272e0a6b","9f88eef818c1461dbf5ca64947d920f3","e7e76f474c224eb2ad7840cda798f340","95d8e6a3c7e047d8a666e1226b062421","27bba64a6cbd493d964bbe56e4b18b5d"]},"id":"eLA6PFhBAHDr","executionInfo":{"status":"ok","timestamp":1728256029955,"user_tz":240,"elapsed":931788,"user":{"displayName":"Ken Clements","userId":"01172872815397642559"}},"outputId":"f93505bc-3860-4e20-b8ef-2f7f9f8b62bf"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"717fc7e80cba4753b350a5774fe4ed4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b45d837e12c24d128ce982477f956368"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb1534e4c07447f5b0590395908685bb"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1: Loss = 0.461618036031723\n","Epoch 2: Loss = 0.013853178359568119\n","Epoch 3: Loss = 0.9304459691047668\n","Test Accuracy: 0.88\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gMk-H0EfB_vN"},"execution_count":null,"outputs":[]}]}